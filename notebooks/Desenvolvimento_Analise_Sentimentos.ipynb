{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMsxNHxuoi2SAtOfIk03tD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelinfopiaui/analise-sentimentos-cpweekend/blob/main/notebooks/Desenvolvimento_Analise_Sentimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 Análise de Sentimentos para a Campus Party Weekend Piauí 2025\n",
        "\n",
        "**Objetivo:** Desenvolver um protótipo de Machine Learning capaz de classificar o sentimento de textos em português (positivo, negativo, neutro) a partir de dados coletados de redes sociais.\n",
        "\n",
        "**Projeto de Extensão:** Engenharia de Computação com IA - UNI-CET\n",
        "\n",
        "**Equipe de Desenvolvedores:**\n",
        "* Rafael Oliveira\n",
        "* Ailton Medeiros\n",
        "* Lais Eulálio\n",
        "* Antônio Wilker\n",
        "* Isaac Aragão\n",
        "* Paula Iranda\n",
        "\n",
        "**Docente Orientador:** Prof. Dr. Artur Felipe da Silva Veloso\n",
        "\n",
        "**Etapas deste Notebook:**\n",
        "1.  **Configuração do Ambiente:** Conexão com o Google Drive e importação de bibliotecas.\n",
        "2.  **Carga e Análise dos Dados:** Carregar o dataset e fazer uma análise exploratória inicial.\n",
        "3.  **Pré-Processamento:** Limpeza e preparação dos textos para o modelo.\n",
        "4.  **Treinamento do Modelo:** Construção, treino e avaliação de um modelo de classificação.\n",
        "5.  **Salvamento do Modelo:** Exportar o modelo treinado para ser usado na aplicação com Streamlit."
      ],
      "metadata": {
        "id": "vQHhp1xurovh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuração do Ambiente\n",
        "\n",
        "Nesta primeira etapa, a equipe irá conectar o Colab ao Google Drive para acessar os dados, importar todas as bibliotecas que serão utilizadas no projeto e definir os caminhos dos arquivos para manter o código organizado e acessível a todos."
      ],
      "metadata": {
        "id": "QuCMDPHGsOWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Configuração do Ambiente\n",
        "\n",
        "# 1.1 - INSTALAÇÃO E UPGRADE DE PACOTES (CRUCIAL PARA CORREÇÃO)\n",
        "!pip install pandas scikit-learn streamlit nltk joblib\n",
        "!pip install numpy --upgrade\n",
        "!pip install scikit-learn --upgrade\n",
        "!pip install joblib --upgrade\n",
        "print(\"Pacotes de ML instalados/atualizados com sucesso!\")\n",
        "\n",
        "# 1.2 - Conectar ao Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1.3 - LIMPEZA DE CACHE DO AMBIENTE (FINAL)\n",
        "# Movemos para o início para que pacotes sejam carregados corretamente\n",
        "%reset -f\n",
        "print(\"\\nCache de pacotes limpo. Recarregando ambiente...\")\n",
        "\n",
        "# 1.4 - REDEFINIR Variáveis e Mudar diretório (APÓS O RESET)\n",
        "# A variável PASTA_PROJETO precisa ser redefinida aqui\n",
        "PASTA_PROJETO = '/content/drive/MyDrive/Projeto_CampusParty_Sentimentos'\n",
        "%cd {PASTA_PROJETO}\n",
        "\n",
        "# 1.5 - Importar bibliotecas essenciais (TUDO SERÁ IMPORTADO A PARTIR DAQUI)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import joblib\n",
        "\n",
        "# 1.6 - Importar módulos do Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1.7 - Definir Caminhos (USANDO A PASTA_PROJETO CORRIGIDA)\n",
        "CAMINHO_DADOS_BRUTOS = f'{PASTA_PROJETO}/data/dataset_bruto.csv'\n",
        "CAMINHO_DADOS_LIMPOS = f'{PASTA_PROJETO}/data/dados_limpos.csv'\n",
        "CAMINHO_MODELO = f'{PASTA_PROJETO}/saved_models/modelo_sentimento.joblib'\n",
        "\n",
        "print(\"\\nAmbiente configurado e pacotes prontos!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D64IZi4bsPEN",
        "outputId": "4af9c127-fa64-4675-8a4a-e73ebdda2dc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: scikit-learn\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed scikit-learn\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-learn\n",
            "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.3.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: scikit-learn\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed scikit-learn\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mPacotes de ML instalados/atualizados com sucesso!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Cache de pacotes limpo. Recarregando ambiente...\n",
            "/content/drive/MyDrive/Projeto_CampusParty_Sentimentos\n",
            "\n",
            "Ambiente configurado e pacotes prontos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Carga e Análise Exploratória dos Dados (EDA)\n",
        "\n",
        "Nesta etapa, a equipe carrega o dataset e realiza uma verificação rápida para entender sua estrutura, a quantidade de dados e a presença de valores nulos.\n",
        "\n",
        "**Nota sobre o Fluxo de Trabalho:** Para garantir a estabilidade e contornar um problema persistente de sincronização com o Google Drive, o carregamento dos dados será feito através do **upload direto** para a sessão do Colab a cada vez que o notebook for iniciado. O código a seguir já está preparado para ler o arquivo deste ambiente local temporário, utilizando os parâmetros de leitura que se provaram eficazes durante os testes."
      ],
      "metadata": {
        "id": "ZCwe-TDfsSla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Carga e Análise Exploratória dos Dados (EDA)\n",
        "\n",
        "# 2.1 - Carregar o dataset\n",
        "try:\n",
        "    df = pd.read_csv(CAMINHO_DADOS_BRUTOS)\n",
        "    print(f\"Dataset carregado com sucesso! Total de linhas: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro: Arquivo não encontrado em '{CAMINHO_DADOS_BRUTOS}'. Verifique o caminho e o nome do arquivo.\")\n",
        "\n",
        "# 2.2 - Mapear colunas do dataset Reddit para o padrão do nosso projeto\n",
        "# O corpo (texto) do comentário.\n",
        "df['texto'] = df['body']\n",
        "# O score (votos) indica sentimento: > 1 é Positivo (1); <= 1 é Negativo/Neutro (0).\n",
        "df['sentimento'] = df['score'].apply(lambda x: 1 if x > 1 else 0)\n",
        "\n",
        "# 2.3 - Visualizar as primeiras linhas\n",
        "print(\"\\nPrimeiras 5 linhas do dataset (após mapeamento):\")\n",
        "display(df[['body', 'score', 'texto', 'sentimento']].head())\n",
        "\n",
        "# 2.4 - Verificar informações gerais\n",
        "print(\"\\nInformações do DataFrame:\")\n",
        "df.info()\n",
        "\n",
        "# 2.5 - Verificar a distribuição das classes de sentimento\n",
        "print(\"\\nDistribuição inicial dos sentimentos (0=Negativo/Neutro, 1=Positivo):\")\n",
        "print(df['sentimento'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "AaoYaorEWQ5M",
        "outputId": "a28967a9-b395-4869-d022-0b17f0d67e91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado com sucesso! Total de linhas: 872153\n",
            "\n",
            "Primeiras 5 linhas do dataset (após mapeamento):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                body  score  \\\n",
              "0  Limpa os cacos com um pano úmido e borrifa àgu...      1   \n",
              "1                                Eu autorizo Xandão       1   \n",
              "2  Tem tanta coisa esquisita acontecendo nessa ci...      1   \n",
              "3  Não é caso de educação,  caráter você nasce co...      1   \n",
              "4                                       Flan é pudim      1   \n",
              "\n",
              "                                               texto  sentimento  \n",
              "0  Limpa os cacos com um pano úmido e borrifa àgu...           0  \n",
              "1                                Eu autorizo Xandão            0  \n",
              "2  Tem tanta coisa esquisita acontecendo nessa ci...           0  \n",
              "3  Não é caso de educação,  caráter você nasce co...           0  \n",
              "4                                       Flan é pudim           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa2933d2-ca83-436d-a910-a19bebd6c800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Limpa os cacos com um pano úmido e borrifa àgu...</td>\n",
              "      <td>1</td>\n",
              "      <td>Limpa os cacos com um pano úmido e borrifa àgu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Eu autorizo Xandão</td>\n",
              "      <td>1</td>\n",
              "      <td>Eu autorizo Xandão</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tem tanta coisa esquisita acontecendo nessa ci...</td>\n",
              "      <td>1</td>\n",
              "      <td>Tem tanta coisa esquisita acontecendo nessa ci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Não é caso de educação,  caráter você nasce co...</td>\n",
              "      <td>1</td>\n",
              "      <td>Não é caso de educação,  caráter você nasce co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flan é pudim</td>\n",
              "      <td>1</td>\n",
              "      <td>Flan é pudim</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa2933d2-ca83-436d-a910-a19bebd6c800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa2933d2-ca83-436d-a910-a19bebd6c800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa2933d2-ca83-436d-a910-a19bebd6c800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5c9cc43a-05ad-4b6e-a5ee-c27e506c3325\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c9cc43a-05ad-4b6e-a5ee-c27e506c3325')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5c9cc43a-05ad-4b6e-a5ee-c27e506c3325 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df['sentimento']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Eu autorizo Xand\\u00e3o\\u00a0\",\n          \"Flan \\u00e9 pudim\",\n          \"Tem tanta coisa esquisita acontecendo nessa cidade.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Eu autorizo Xand\\u00e3o\\u00a0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentimento\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informações do DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 872153 entries, 0 to 872152\n",
            "Data columns (total 14 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   author         872153 non-null  object\n",
            " 1   body           872151 non-null  object\n",
            " 2   created_utc    872153 non-null  object\n",
            " 3   distinguished  8641 non-null    object\n",
            " 4   edited         872153 non-null  object\n",
            " 5   comment_id     872153 non-null  object\n",
            " 6   is_submitter   872153 non-null  bool  \n",
            " 7   parent_id      872153 non-null  object\n",
            " 8   score          872153 non-null  int64 \n",
            " 9   stickied       872153 non-null  bool  \n",
            " 10  thread_id      872153 non-null  object\n",
            " 11  version        872153 non-null  int64 \n",
            " 12  texto          872151 non-null  object\n",
            " 13  sentimento     872153 non-null  int64 \n",
            "dtypes: bool(2), int64(3), object(9)\n",
            "memory usage: 81.5+ MB\n",
            "\n",
            "Distribuição inicial dos sentimentos (0=Negativo/Neutro, 1=Positivo):\n",
            "sentimento\n",
            "1    0.641596\n",
            "0    0.358404\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Limpeza Inicial do DataFrame\n",
        "\n",
        "Com os dados brutos carregados no DataFrame `df`, o primeiro passo é uma \"faxina\" estrutural para tornar o dataset mais limpo e fácil de trabalhar. As seguintes ações serão tomadas:\n",
        "\n",
        "1.  **Limpeza dos Nomes das Colunas:** As aspas extras (`\"`) presentes nos nomes das colunas serão removidas.\n",
        "2.  **Remoção de Linhas Vazias:** As linhas que não contêm comentários (valores nulos na coluna `body`) serão eliminadas, pois são inúteis para a nossa análise de sentimentos.\n",
        "3.  **Seleção de Colunas Relevantes:** Um novo DataFrame, `df_final`, será criado contendo apenas as colunas mais importantes para o nosso estudo (`author`, `body`, `score`, `created_utc`)."
      ],
      "metadata": {
        "id": "DbRVhfVyd1XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Limpeza Inicial do DataFrame\n",
        "\n",
        "# 3.1 - Remoção de linhas com texto vazio ou nulo nas colunas chave\n",
        "linhas_antes = len(df)\n",
        "df.dropna(subset=['texto', 'sentimento'], inplace=True)\n",
        "df = df[df['texto'].str.strip() != ''] # Remove linhas onde o texto está vazio ou só contém espaços\n",
        "\n",
        "linhas_depois = len(df)\n",
        "print(f\"Linhas removidas devido a valores nulos ou vazios: {linhas_antes - linhas_depois}\")\n",
        "print(f\"Total de amostras válidas para o pré-processamento: {linhas_depois}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQcmxXxcd2RK",
        "outputId": "2014e31f-49bb-4fbe-a7f3-1ad618ea9758"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas removidas devido a valores nulos ou vazios: 2\n",
            "Total de amostras válidas para o pré-processamento: 872151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pré-processamento Profundo do Texto\n",
        "\n",
        "Com o DataFrame estruturalmente limpo, o próximo passo é processar o conteúdo da coluna `body`. Nesta etapa, vamos aplicar uma função de limpeza em cada comentário para:\n",
        "\n",
        "- Padronizar o texto (converter para letras minúsculas).\n",
        "- Remover \"ruídos\" como URLs, menções de usuários e caracteres especiais.\n",
        "- Remover palavras comuns que não carregam sentimento (stopwords como 'o', 'a', 'de', 'que').\n",
        "\n",
        "O resultado será salvo em uma nova coluna, `body_limpo`, que servirá de base para o nosso modelo de Machine Learning."
      ],
      "metadata": {
        "id": "ow56OgP3eK1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Pré-processamento Profundo do Texto\n",
        "\n",
        "# 4.1 - Definir a função de limpeza de texto\n",
        "def limpar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'https?://\\S+|www\\.\\S+', '', texto) # Remover URLs\n",
        "    texto = re.sub(r'@\\w+|#\\w+', '', texto)             # Remover menções e hashtags\n",
        "    texto = re.sub(r'[^a-z\\s]', '', texto)              # Remover caracteres não-alfabéticos\n",
        "\n",
        "    tokens = nltk.word_tokenize(texto)\n",
        "    stopwords_pt = nltk.corpus.stopwords.words('portuguese')\n",
        "    tokens_limpos = [palavra for palavra in tokens if palavra not in stopwords_pt]\n",
        "\n",
        "    return ' '.join(tokens_limpos)\n",
        "\n",
        "# 4.2 - Aplicar a função de limpeza na coluna de texto\n",
        "print(\"[Passo 1/2] Aplicando limpeza profunda do texto...\")\n",
        "df['texto_limpo'] = df['texto'].apply(limpar_texto)\n",
        "\n",
        "# 4.3 - SALVAMENTO DO DATASET LIMPO (Correção de salvamento)\n",
        "print(\"\\n[Passo 2/2] Salvando o dataset limpo para uso futuro...\")\n",
        "try:\n",
        "    # Salva apenas o texto limpo e a classificação de sentimento\n",
        "    df[['texto_limpo', 'sentimento']].to_csv(CAMINHO_DADOS_LIMPOS, index=False)\n",
        "    print(f\"✅ Dataset limpo salvo com sucesso em: {CAMINHO_DADOS_LIMPOS}\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRO ao salvar dados limpos: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUyFgCW9eMo2",
        "outputId": "e2415765-4ce0-4537-fcc7-fd1b64d48b5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Passo 1/2] Aplicando limpeza profunda do texto...\n",
            "\n",
            "[Passo 2/2] Salvando o dataset limpo para uso futuro...\n",
            "✅ Dataset limpo salvo com sucesso em: /content/drive/MyDrive/Projeto_CampusParty_Sentimentos/data/dados_limpos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Construção, Treinamento e Avaliação do Modelo\n",
        "\n",
        "Esta é a etapa central do projeto. Com os dados limpos e pré-processados no DataFrame `df_final`, vamos:\n",
        "\n",
        "1.  **Criar a Variável Alvo (`y`):** Como nosso dataset não possui uma coluna de sentimento, usaremos a coluna `score` (a pontuação do comentário) como um substituto (*proxy*). Comentários com score alto (>1) serão considerados \"positivos\", e os demais, \"negativos/neutros\".\n",
        "2.  **Dividir os Dados:** Separar o dataset em um conjunto de **treino** (para o modelo aprender) e um conjunto de **teste** (para avaliarmos o quão bem ele aprendeu).\n",
        "3.  **Construir um `Pipeline`:** Criar uma esteira de produção que primeiro transforma o texto limpo em vetores numéricos (`TfidfVectorizer`) e depois os usa para treinar um modelo de classificação (`LogisticRegression`).\n",
        "4.  **Treinar e Avaliar:** Executar o treinamento e verificar a performance do modelo com métricas como a acurácia."
      ],
      "metadata": {
        "id": "p_kod75BjZEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Construção, Treinamento e Avaliação do Modelo\n",
        "\n",
        "print(\"\\n--- Iniciando a Construção e Treinamento do Modelo ---\")\n",
        "\n",
        "# 1. Definir X (features) e y (target)\n",
        "# Usamos a coluna 'texto_limpo' (do Bloco 4) e a coluna 'sentimento' (do Bloco 3)\n",
        "print(\"[Passo 1/4] Definindo variáveis X e y...\")\n",
        "X = df['texto_limpo']\n",
        "y = df['sentimento']\n",
        "\n",
        "# 2. Dividir em treino e teste\n",
        "# O stratify=y garante que a divisão mantenha a proporção de sentimentos\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Total de amostras de treino: {len(X_train):,} amostras. Total de teste: {len(X_test):,} amostras.\")\n",
        "\n",
        "# 3. Construir o Pipeline do modelo\n",
        "print(\"\\n[Passos 3/4] Construindo o pipeline do modelo...\")\n",
        "# O Pipeline aplica primeiro o TF-IDF (vetorização) e depois a Regressão Logística (classificação)\n",
        "modelo_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# 4. Treinar o modelo\n",
        "print(\"\\n[Passos 4/4] Iniciando o treinamento do modelo (isso leva alguns minutos)...\")\n",
        "modelo_pipeline.fit(X_train, y_train)\n",
        "print(\"✅ Treinamento concluído!\")\n",
        "\n",
        "# 5. Fazer previsões no conjunto de teste e avaliar o modelo\n",
        "y_pred = modelo_pipeline.predict(X_test)\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- PERFORMANCE DO MODELO ---\")\n",
        "print(f\"Acurácia: {acuracia:.4f}\")\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SedJoPxxjaGT",
        "outputId": "e15cc251-4f91-4483-d5b2-0cee28d34b25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando a Construção e Treinamento do Modelo ---\n",
            "[Passo 1/4] Definindo variáveis X e y...\n",
            "Total de amostras de treino: 697,720 amostras. Total de teste: 174,431 amostras.\n",
            "\n",
            "[Passos 3/4] Construindo o pipeline do modelo...\n",
            "\n",
            "[Passos 4/4] Iniciando o treinamento do modelo (isso leva alguns minutos)...\n",
            "✅ Treinamento concluído!\n",
            "\n",
            "--- PERFORMANCE DO MODELO ---\n",
            "Acurácia: 0.6534\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.16      0.24     62516\n",
            "           1       0.66      0.93      0.78    111915\n",
            "\n",
            "    accuracy                           0.65    174431\n",
            "   macro avg       0.61      0.54      0.51    174431\n",
            "weighted avg       0.63      0.65      0.59    174431\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Salvando o Pipeline Final\n",
        "\n",
        "Com o modelo treinado e avaliado, a etapa final é salvar o objeto `modelo_pipeline` em um arquivo. Isso nos permite reutilizar o modelo treinado no futuro (por exemplo, em nosso dashboard com Streamlit) sem a necessidade de retreiná-lo toda vez.\n",
        "\n",
        "Usaremos a biblioteca `joblib` para salvar o modelo e, em seguida, a `google.colab.files` para baixá-lo para nosso computador."
      ],
      "metadata": {
        "id": "VWj1F6U6j0f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Salvando o Pipeline Final\n",
        "\n",
        "print(\"\\n--- SALVAMENTO DO PIPELINE ---\")\n",
        "\n",
        "# Esta é a última correção. Garantimos que a variável CAMINHO_MODELO (que aponta para saved_models/) seja usada.\n",
        "try:\n",
        "    # 6.1 - Salva o Pipeline no Google Drive (na pasta saved_models/)\n",
        "    joblib.dump(modelo_pipeline, CAMINHO_MODELO)\n",
        "    print(f\"✅ Pipeline do modelo salvo com sucesso em: {CAMINHO_MODELO}\")\n",
        "\n",
        "    # 6.2 - GERA O DOWNLOAD DIRETO (Recurso solicitado)\n",
        "    from google.colab import files\n",
        "    # Garante que o arquivo seja baixado com o nome correto\n",
        "    files.download(CAMINHO_MODELO)\n",
        "    print(\"\\n⬇️ Download iniciado! Baixe o arquivo 'modelo_sentimento.joblib' para sua máquina.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERRO ao salvar e baixar o modelo: {e}\")\n",
        "\n",
        "print(\"\\nFim do Notebook. O novo modelo está pronto para ser usado no Streamlit!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "MZLnbkx0j2K1",
        "outputId": "c9658a5f-7d0a-4301-be03-6abe9584592e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SALVAMENTO DO PIPELINE ---\n",
            "✅ Pipeline do modelo salvo com sucesso em: /content/drive/MyDrive/Projeto_CampusParty_Sentimentos/saved_models/modelo_sentimento.joblib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_296c9614-8fb7-4a5c-bf75-510edba13232\", \"modelo_sentimento.joblib\", 7227444)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⬇️ Download iniciado! Baixe o arquivo 'modelo_sentimento.joblib' para sua máquina.\n",
            "\n",
            "Fim do Notebook. O novo modelo está pronto para ser usado no Streamlit!\n"
          ]
        }
      ]
    }
  ]
}